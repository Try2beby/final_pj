{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "from utils.global_rules import rules\n",
    "\n",
    "dataDir = \"../data/\"\n",
    "cacheDir = \"../data/cache/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读入图数据，G: 无向图，G_directed: 有向图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph...\n",
      "Initial Node shape:  (2371558, 4)\n",
      "Initial Link shape:  (3286986, 3)\n",
      "After drop nan and duplicates:\n",
      "Node shape:  (2371558, 4)\n",
      "Link shape:  (3285490, 3)\n",
      "Undirected graph loaded.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "process = importlib.import_module(\"process\")\n",
    "importlib.reload(process)\n",
    "\n",
    "G = process.get_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Directed Graph from the undirected one\n",
    "G_directed = nx.DiGraph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行社区检测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "community_detection = importlib.import_module(\"utils.community_detection\")\n",
    "importlib.reload(community_detection)\n",
    "\n",
    "# community_detection.get_community_for_all_groups(G)\n",
    "community_detection.get_subgraph_for_all_communities(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据以上社区检测算法的结果，选取团伙 [?] 进行分析。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyse group:  1\n",
      "#nodes in subgraph:  33821\n",
      "#edges in subgraph:  33974\n",
      "Nodes left:  210\n",
      "Edges left:  307\n",
      "Nodes with non-empty industry: 142 / 193\n",
      "\n",
      "analyse group:  2\n",
      "#nodes in subgraph:  5125\n",
      "#edges in subgraph:  5853\n",
      "Nodes left:  563\n",
      "Edges left:  940\n",
      "Nodes with non-empty industry: 382 / 534\n",
      "\n",
      "analyse group:  3\n",
      "#nodes in subgraph:  36149\n",
      "#edges in subgraph:  37891\n",
      "Nodes left:  624\n",
      "Edges left:  1305\n",
      "Nodes with non-empty industry: 103 / 338\n",
      "\n",
      "analyse group:  4\n",
      "#nodes in subgraph:  27268\n",
      "#edges in subgraph:  32401\n",
      "Nodes left:  2265\n",
      "Edges left:  4443\n",
      "Nodes with non-empty industry: 801 / 1992\n",
      "\n",
      "analyse group:  5\n",
      "#nodes in subgraph:  18534\n",
      "#edges in subgraph:  20714\n",
      "Nodes left:  1951\n",
      "Edges left:  3252\n",
      "Nodes with non-empty industry: 1028 / 1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import importlib\n",
    "import pandas as pd\n",
    "\n",
    "rules = importlib.import_module(\"utils.global_rules\")\n",
    "process = importlib.import_module(\"process\")\n",
    "importlib.reload(rules)\n",
    "importlib.reload(process)\n",
    "\n",
    "rules = rules.rules\n",
    "# group_to_analyze = [\"1\", \"3\", \"4\"]\n",
    "group_to_analyze = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "# group_to_analyze = [\"1\", \"2\", \"4\", \"5\"]\n",
    "cacheDir = \"../data/cache/\"\n",
    "subgraphDir = \"../data/subgraph/\"\n",
    "tempDir = \"../data/temp/\"\n",
    "answerDir = \"../data/answer/\"\n",
    "\n",
    "params = {\n",
    "    \"1\": {\n",
    "        \"pagerankQuantile\": 0.95,\n",
    "        \"degreeCentralityQuantile\": 0.95,\n",
    "        \"degreeQuantile\": 0.8,\n",
    "        \"jump_limit\": rules[\"jump_limit_specified_by_industry\"][\"1\"],\n",
    "        \"countKeepPercent\": 0.1,\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"pagerankQuantile\": 0.92,\n",
    "        \"degreeCentralityQuantile\": 0.92,\n",
    "        \"degreeQuantile\": 0.9,\n",
    "        \"jump_limit\": rules[\"jump_limit_specified_by_industry\"][\"2\"],\n",
    "        \"countKeepPercent\": 0.6,\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"pagerankQuantile\": 0.95,\n",
    "        \"degreeCentralityQuantile\": 0.95,\n",
    "        \"degreeQuantile\": 0.94,\n",
    "        \"jump_limit\": rules[\"jump_limit_specified_by_industry\"][\"3\"],\n",
    "        \"countKeepPercent\": 0.4,\n",
    "    },\n",
    "    \"4\": {\n",
    "        \"pagerankQuantile\": 0.9,\n",
    "        \"degreeCentralityQuantile\": 0.88,\n",
    "        \"degreeQuantile\": 0.82,\n",
    "        \"jump_limit\": rules[\"jump_limit_specified_by_industry\"][\"4\"],\n",
    "        \"countKeepPercent\": 0.4,\n",
    "    },\n",
    "    \"5\": {\n",
    "        \"pagerankQuantile\": 0.7,\n",
    "        \"degreeCentralityQuantile\": 0.7,\n",
    "        \"degreeQuantile\": 0.85,\n",
    "        \"jump_limit\": rules[\"jump_limit_specified_by_industry\"][\"5\"],\n",
    "        \"countKeepPercent\": 0.4,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def export_subgraph(graph, group_str: str):\n",
    "    # transform the graph to directed graph\n",
    "    # graph = graph.to_directed()\n",
    "    # export the graph to json\n",
    "    data = nx.readwrite.json_graph.node_link_data(graph)\n",
    "    # Keep only the nodes and edges\n",
    "    data = {\"nodes\": data[\"nodes\"], \"edges\": data[\"links\"]}\n",
    "    json.dump(\n",
    "        data,\n",
    "        open(tempDir + \"group_\" + group_str + \".json\", \"w\"),\n",
    "        indent=4,\n",
    "    )\n",
    "\n",
    "    json.dump(\n",
    "        nx.readwrite.json_graph.node_link_data(graph),\n",
    "        open(subgraphDir + \"group_\" + group_str + \".json\", \"w\"),\n",
    "        indent=4,\n",
    "    )\n",
    "\n",
    "    # Create a directory in subgraphDir\n",
    "    if not os.path.exists(subgraphDir + group_str):\n",
    "        os.makedirs(subgraphDir + group_str)\n",
    "\n",
    "    node_data = pd.DataFrame(data[\"nodes\"])\n",
    "    node_data.to_csv(subgraphDir + group_str + \"/nodes.csv\", index=False)\n",
    "    link_data = pd.DataFrame(data[\"edges\"])\n",
    "    link_data.to_csv(subgraphDir + group_str + \"/links.csv\", index=False)\n",
    "\n",
    "    if not os.path.exists(answerDir + group_str):\n",
    "        os.makedirs(answerDir + group_str)\n",
    "\n",
    "    # export node in format: id, name, type, industry\n",
    "    node_data[[\"id\", \"name\", \"type\", \"industry\"]].to_csv(\n",
    "        answerDir + group_str + \"/nodes.csv\", index=False\n",
    "    )\n",
    "    # export link in format: relation, source, target\n",
    "    link_data[[\"relation\", \"source\", \"target\"]].to_csv(\n",
    "        answerDir + group_str + \"/links.csv\", index=False\n",
    "    )\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def analyse_group(group_str: str):\n",
    "    print(\"analyse group: \", group_str)\n",
    "    # get the evidence\n",
    "    evidence = rules[\"evidence\"][group_str]\n",
    "\n",
    "    # # read the group\n",
    "    # graph = nx.readwrite.json_graph.node_link_graph(\n",
    "    #     json.load(open(cacheDir + \"group_\" + group_str + \".json\"))\n",
    "    # )\n",
    "\n",
    "    subgraph = process.get_subgraph(G, evidence, params[group_str][\"jump_limit\"])\n",
    "\n",
    "    process.set_core(subgraph)\n",
    "\n",
    "    subgraph_filtered = process.filter_subgraph(\n",
    "        subgraph,\n",
    "        pagerankQuantile=params[group_str][\"pagerankQuantile\"],\n",
    "        degreeCentralityQuantile=params[group_str][\"degreeCentralityQuantile\"],\n",
    "        degreeQuantile=params[group_str][\"degreeQuantile\"],\n",
    "        countKeepPercent=params[group_str][\"countKeepPercent\"],\n",
    "        scaleThreshold=rules[\"net_limit\"][rules[\"scale\"][group_str]][\"node\"],\n",
    "        # verbose=True,\n",
    "    )\n",
    "    export_subgraph(subgraph_filtered, group_str)\n",
    "\n",
    "    print()\n",
    "    return\n",
    "\n",
    "\n",
    "for group in group_to_analyze:\n",
    "    analyse_group(group)\n",
    "\n",
    "# analyse_group(\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group:  1\n",
      "group:  2\n",
      "group:  3\n",
      "group:  4\n",
      "group:  5\n",
      "find key path for group:  1\n",
      "#nodes:  210\n",
      "#edges:  307\n",
      "find key path for group:  2\n",
      "#nodes:  563\n",
      "#edges:  940\n",
      "find key path for group:  3\n",
      "#nodes:  624\n",
      "#edges:  1305\n",
      "find key path for group:  4\n",
      "#nodes:  2265\n",
      "#edges:  4443\n",
      "find key path for group:  5\n",
      "#nodes:  1951\n",
      "#edges:  3252\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "count = importlib.import_module(\"utils.count\")\n",
    "keypath = importlib.import_module(\"utils.key_nodes_path\")\n",
    "importlib.reload(count)\n",
    "importlib.reload(keypath)\n",
    "\n",
    "count.count_type_for_all_groups(group_to_analyze)\n",
    "keypath.find_key_path_for_all_groups(group_to_analyze)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
