{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "from utils.global_rules import rules\n",
    "\n",
    "dataDir = \"../data/\"\n",
    "cacheDir = \"../data/cache/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读入图数据，G: 无向图，G_directed: 有向图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph...\n",
      "Initial Node shape:  (2371558, 4)\n",
      "Initial Link shape:  (3286986, 3)\n",
      "After drop nan and duplicates:\n",
      "Node shape:  (2371558, 4)\n",
      "Link shape:  (3285490, 3)\n",
      "Undirected graph loaded.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "process = importlib.import_module(\"process\")\n",
    "importlib.reload(process)\n",
    "\n",
    "G = process.get_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Directed Graph from the undirected one\n",
    "G_directed = nx.DiGraph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行社区检测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "community_detection = importlib.import_module(\"utils.community_detection\")\n",
    "importlib.reload(community_detection)\n",
    "\n",
    "# community_detection.get_community_for_all_groups(G)\n",
    "community_detection.get_subgraph_for_all_communities(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据以上社区检测算法的结果，选取团伙 [?] 进行分析。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyse group:  1\n",
      "#nodes in subgraph:  30767\n",
      "#edges in subgraph:  82663\n",
      "Filtering nodes...\n",
      "Removing nodes by count...\n",
      "Nodes removed:  9805 Nodes left:  20962\n",
      "Removing nodes with empty industry and low degree...\n",
      "Nodes removed:  2123 Nodes left:  18839\n",
      "Removing nodes by pagerank quantile and degree centrality...\n",
      "Nodes removed:  17657 Nodes left:  1182\n",
      "Keeping the max connected component...\n",
      "Nodes left:  507\n",
      "\n",
      "analyse group:  2\n",
      "#nodes in subgraph:  296\n",
      "#edges in subgraph:  1227\n",
      "Filtering nodes...\n",
      "Removing nodes by count...\n",
      "Nodes removed:  139 Nodes left:  157\n",
      "Removing nodes with empty industry and low degree...\n",
      "Nodes removed:  1 Nodes left:  156\n",
      "Removing nodes by pagerank quantile and degree centrality...\n",
      "Nodes removed:  145 Nodes left:  11\n",
      "Keeping the max connected component...\n",
      "Nodes left:  3\n",
      "\n",
      "analyse group:  3\n",
      "#nodes in subgraph:  33220\n",
      "#edges in subgraph:  69459\n",
      "Filtering nodes...\n",
      "Removing nodes by count...\n",
      "Nodes removed:  5313 Nodes left:  27907\n",
      "Removing nodes with empty industry and low degree...\n",
      "Nodes removed:  1390 Nodes left:  26517\n",
      "Removing nodes by pagerank quantile and degree centrality...\n",
      "Nodes removed:  25138 Nodes left:  1379\n",
      "Keeping the max connected component...\n",
      "Nodes left:  1247\n",
      "\n",
      "analyse group:  4\n",
      "#nodes in subgraph:  14899\n",
      "#edges in subgraph:  28722\n",
      "Filtering nodes...\n",
      "Removing nodes by count...\n",
      "Nodes removed:  5068 Nodes left:  9831\n",
      "Removing nodes with empty industry and low degree...\n",
      "Nodes removed:  31 Nodes left:  9800\n",
      "Removing nodes by pagerank quantile and degree centrality...\n",
      "Nodes removed:  8546 Nodes left:  1254\n",
      "Keeping the max connected component...\n",
      "Nodes left:  1191\n",
      "\n",
      "analyse group:  5\n",
      "#nodes in subgraph:  6760\n",
      "#edges in subgraph:  8885\n",
      "Filtering nodes...\n",
      "Removing nodes by count...\n",
      "Nodes removed:  2539 Nodes left:  4221\n",
      "Removing nodes with empty industry and low degree...\n",
      "Nodes removed:  93 Nodes left:  4128\n",
      "Removing nodes by pagerank quantile and degree centrality...\n",
      "Nodes removed:  2729 Nodes left:  1399\n",
      "Keeping the max connected component...\n",
      "Nodes left:  1397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import importlib\n",
    "\n",
    "rules = importlib.import_module(\"utils.global_rules\")\n",
    "process = importlib.import_module(\"process\")\n",
    "importlib.reload(rules)\n",
    "importlib.reload(process)\n",
    "\n",
    "rules = rules.rules\n",
    "# group_to_analyze = [\"1\", \"3\", \"4\"]\n",
    "group_to_analyze = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "cacheDir = \"../data/cache/\"\n",
    "subgraphDir = \"../data/subgraph/\"\n",
    "tempDir = \"../data/temp/\"\n",
    "\n",
    "\n",
    "def export_subgraph_to_json(graph, group_str: str):\n",
    "    # transform the graph to directed graph\n",
    "    # graph = graph.to_directed()\n",
    "    # export the graph to json\n",
    "    data = nx.readwrite.json_graph.node_link_data(graph)\n",
    "    # Keep only the nodes and edges\n",
    "    data = {\"nodes\": data[\"nodes\"], \"edges\": data[\"links\"]}\n",
    "    json.dump(\n",
    "        data,\n",
    "        open(tempDir + \"group_\" + group_str + \".json\", \"w\"),\n",
    "        indent=4,\n",
    "    )\n",
    "\n",
    "    json.dump(\n",
    "        nx.readwrite.json_graph.node_link_data(graph),\n",
    "        open(subgraphDir + \"group_\" + group_str + \".json\", \"w\"),\n",
    "        indent=4,\n",
    "    )\n",
    "    return\n",
    "\n",
    "\n",
    "def analyse_group(group_str: str):\n",
    "    print(\"analyse group: \", group_str)\n",
    "    # get the evidence\n",
    "    evidence = rules[\"evidence\"][group_str]\n",
    "\n",
    "    # # read the group\n",
    "    # graph = nx.readwrite.json_graph.node_link_graph(\n",
    "    #     json.load(open(cacheDir + \"group_\" + group_str + \".json\"))\n",
    "    # )\n",
    "    # # print graph info\n",
    "    # print(\"#nodes: \", graph.number_of_nodes())\n",
    "    # print(\"#edges: \", graph.number_of_edges())\n",
    "    # subgraph = process.get_subgrah(graph, evidence)\n",
    "\n",
    "    subgraph = process.get_subgraph(G, evidence)\n",
    "    print(\"#nodes in subgraph: \", subgraph.number_of_nodes())\n",
    "    print(\"#edges in subgraph: \", subgraph.number_of_edges())\n",
    "\n",
    "    subgraph_filtered = process.filter_subgraph(\n",
    "        subgraph, countKeepPercent=0.6, pagerankQuantile=0.96\n",
    "    )\n",
    "    process.set_core(subgraph_filtered)\n",
    "    export_subgraph_to_json(subgraph_filtered, group_str)\n",
    "\n",
    "    print()\n",
    "    return\n",
    "\n",
    "\n",
    "for group in group_to_analyze:\n",
    "    analyse_group(group)\n",
    "\n",
    "# analyse_group(\"1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
